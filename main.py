from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import Optional, List
import numpy as np
import cv2

app = FastAPI(
    title="AI Kiosk - AI Server",
    description="MediaPipe Poseì™€ FaceMeshìš© ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ë™ ì„œë²„",
    version="0.2.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/", response_class=HTMLResponse)
async def root():
    """Hello World í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>AI Kiosk - AI Server</title>
        <style>
            body {
                font-family: system-ui, -apple-system, sans-serif;
                display: flex;
                justify-content: center;
                align-items: center;
                height: 100vh;
                margin: 0;
                background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
                color: white;
            }
            div {
                text-align: center;
            }
            h1 {
                font-size: 3rem;
                margin-bottom: 1rem;
            }
            p {
                font-size: 1.2rem;
                opacity: 0.9;
            }
            .tech {
                margin-top: 2rem;
                font-size: 0.9rem;
                opacity: 0.7;
            }
        </style>
    </head>
    <body>
        <div>
            <h1>ğŸ¤– AI Kiosk - AI Server</h1>
            <p>Hello World! FastAPI Server is running.</p>
            <p class="tech">Python + FastAPI + MediaPipe + OpenAI</p>
            <p style="margin-top: 2rem; font-size: 0.9rem; opacity: 0.7">FusionCrew Â© 2025~2026</p>
        </div>
    </body>
    </html>
    """


@app.get("/health")
async def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok"}


@app.get("/api/ping")
async def ping():
    """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    return {"message": "pong", "server": "ai-server"}


# ============================================
# Hesitation Detection API
# ============================================

class HesitationResponse(BaseModel):
    """ë§ì„¤ì„ ê°ì§€ ì‘ë‹µ ëª¨ë¸"""
    hesitation_level: int
    confidence: float
    label: str
    probabilities: Optional[List[float]] = None
    error: Optional[str] = None


class Base64ImageRequest(BaseModel):
    """Base64 ì´ë¯¸ì§€ ìš”ì²­ ëª¨ë¸"""
    image: str  # Base64 encoded image
    binary: bool = False  # ì´ì§„ ë¶„ë¥˜ ëª¨ë“œ


@app.post("/api/hesitation/detect", response_model=HesitationResponse)
async def detect_hesitation_from_image(image: UploadFile = File(...)):
    """
    ì´ë¯¸ì§€ì—ì„œ ë§ì„¤ì„ ì •ë„ ê°ì§€
    
    - **image**: ì´ë¯¸ì§€ íŒŒì¼ (JPEG, PNG ë“±)
    - Returns: ë§ì„¤ì„ ë ˆë²¨ (0-3), ì‹ ë¢°ë„, ë¼ë²¨
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await image.read()
        nparr = np.frombuffer(contents, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if img is None:
            raise HTTPException(status_code=400, detail="Failed to decode image")
        
        # ë§ì„¤ì„ ê°ì§€
        from hesitation.inference import detect_hesitation
        result = detect_hesitation(img, binary=False)
        
        return HesitationResponse(**result)
        
    except ImportError:
        raise HTTPException(
            status_code=503,
            detail="Hesitation detection model not available. Please train the model first."
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/hesitation/detect-base64", response_model=HesitationResponse)
async def detect_hesitation_from_base64(request: Base64ImageRequest):
    """
    Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì—ì„œ ë§ì„¤ì„ ê°ì§€
    
    - **image**: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´
    - **binary**: Trueë©´ ì´ì§„ ë¶„ë¥˜ (ë§ì„¤ì„/ë¹„ë§ì„¤ì„)
    - Returns: ë§ì„¤ì„ ë ˆë²¨, ì‹ ë¢°ë„, ë¼ë²¨
    """
    try:
        from hesitation.inference import get_detector
        detector = get_detector(binary=request.binary)
        result = detector.detect_from_base64(request.image)
        
        return HesitationResponse(**result)
        
    except ImportError:
        raise HTTPException(
            status_code=503,
            detail="Hesitation detection model not available. Please train the model first."
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/hesitation/status")
async def hesitation_model_status():
    """ë§ì„¤ì„ ê°ì§€ ëª¨ë¸ ìƒíƒœ í™•ì¸"""
    from pathlib import Path
    from hesitation.config import MODEL_PATH, SCALER_PATH
    
    model_exists = MODEL_PATH.exists()
    scaler_exists = SCALER_PATH.exists()
    
    return {
        "model_available": model_exists and scaler_exists,
        "model_path": str(MODEL_PATH),
        "message": "Model ready" if (model_exists and scaler_exists) else "Model not trained yet"
    }


# STT, LLM ë“± AI ê¸°ëŠ¥ì€ ì¶”í›„ êµ¬í˜„
# @app.post("/api/stt")
# @app.post("/api/llm")
# @app.post("/api/recommend")
